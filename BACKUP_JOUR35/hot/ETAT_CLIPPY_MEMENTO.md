# üìé √âtat Actuel de Clippy/Memento

## üîç CE QUI EXISTE

### 1. **Service Vector DB** ‚úÖ
- **Connexion via Rust** : Port 3001 (`/api/archives/*`)
- **Connexion directe Python** : Port 5001 (fallback)
- **2 modes de recherche** :
  - `story` : Lore, sc√©narios, contenu narratif
  - `dev` : Documentation technique, API

### 2. **Impl√©mentations Clippy** ‚úÖ
- **Version React** : `apps/world-editor/src/lib/clippy.tsx`
- **Version HTML** : Dans index.html, manuels, etc.
- **Service** : `vectorDB.ts` pour les requ√™tes

### 3. **Indexation du contenu** ‚úÖ
- Scripts Python pour indexer `/hot`
- FAISS pour les embeddings locaux
- ~8000 fichiers index√©s

---

## ‚ùå CE QUI NE MARCHE PAS ENCORE

### 1. **Mode LLM** üöß
**Pr√©vu mais pas impl√©ment√© :**
```javascript
// CE QU'ON VOULAIT
- Ollama ou llama.cpp local
- R√©ponses enrichies avec contexte
- Auto-compl√©tion de code
- Suggestions intelligentes

// CE QU'ON A
- Recherche s√©mantique basique
- Tips pr√©d√©finis
- Pas d'intelligence r√©elle
```

### 2. **Intelligence Contextuelle** üöß
```javascript
// MANQUE :
- Comprendre o√π tu es dans le jeu
- Proposer des actions pertinentes
- M√©moriser tes pr√©f√©rences
- Apprendre de tes actions
```

### 3. **Memento (M√©moire)** üöß
```javascript
// PAS ENCORE FAIT :
- Syst√®me de tatouages/m√©moire
- Persistance des apprentissages
- Profil joueur personnalis√©
```

---

## üîß COMMENT ACTIVER CE QUI EXISTE

### 1. **Lancer le Vector DB**
```bash
# M√©thode 1 : Via Rust (recommand√©)
cd magic-stack
./h-profondeur start
# Le Vector DB est inclus dans le backend Rust

# M√©thode 2 : Python direct
python3 backends/python/app.py
```

### 2. **Tester la connexion**
```bash
# Via Rust
curl http://localhost:3001/api/archives/status | jq

# Direct Python
curl http://localhost:5001/health
```

### 3. **Faire une recherche**
```bash
# Mode STORY (lore, sc√©narios)
curl -X POST http://localhost:3001/api/archives/search \
  -H "Content-Type: application/json" \
  -d '{"query": "Merlin temporal", "mode": "story", "top_k": 5}' | jq

# Mode DEV (documentation)
curl -X POST http://localhost:3001/api/archives/search \
  -H "Content-Type: application/json" \
  -d '{"query": "v2 controller", "mode": "dev", "top_k": 5}' | jq
```

---

## üöÄ CE QU'IL FAUT FAIRE POUR LE MODE LLM

### Phase 1 : Installation LLM Local
```bash
# Option 1 : Ollama (plus simple)
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3.2:3b  # Mod√®le l√©ger

# Option 2 : llama.cpp (plus flexible)
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp && make
# T√©l√©charger un mod√®le GGUF
```

### Phase 2 : Int√©gration
```javascript
// clippy-llm.js
class ClippyLLM {
  constructor() {
    this.vectorDB = new VectorDBService();
    this.llm = new OllamaClient(); // ou LlamaCpp
  }
  
  async getSmartResponse(query, context) {
    // 1. Recherche Vector DB
    const docs = await this.vectorDB.search(query);
    
    // 2. Construire le prompt
    const prompt = `
      Contexte: ${docs.join('\n')}
      Question: ${query}
      R√©ponds comme Clippy, l'assistant magique.
    `;
    
    // 3. Appel LLM
    return await this.llm.generate(prompt);
  }
}
```

### Phase 3 : Modes hybrides
```javascript
// Mode 1 : Vector Only (rapide, <100ms)
if (simpleQuery) {
  return vectorDB.search(query);
}

// Mode 2 : Vector + LLM (intelligent, ~1-2s)
if (complexQuery) {
  const context = await vectorDB.search(query);
  return llm.enrich(context, query);
}
```

---

## üìä Comparaison des 2 modes

| Aspect | Mode Vector (Actuel) | Mode LLM (√Ä faire) |
|--------|---------------------|-------------------|
| **Vitesse** | <100ms ‚ö° | 1-2s üê¢ |
| **Intelligence** | Recherche basique | Compr√©hension profonde |
| **Co√ªt** | Gratuit | CPU/GPU local |
| **Personnalisation** | Limit√©e | Compl√®te |
| **Offline** | ‚úÖ Oui | ‚úÖ Oui |
| **Taille** | ~5MB indexes | +4GB mod√®le |

---

## ‚úÖ Recommandation

**Pour l'instant, le mode Vector suffit** pour :
- Recherche dans le lore
- Tips contextuels basiques
- Documentation rapide

**Ajouter le mode LLM quand tu veux** :
- Auto-compl√©tion de code
- Conversations complexes
- G√©n√©ration de contenu
- Tutoriel interactif personnalis√©

---

## üéÆ Test rapide

Ouvre n'importe quel HTML du jeu et clique sur Clippy (üìé). 
- Si tips g√©n√©riques ‚Üí Vector DB pas connect√©
- Si tips contextuels ‚Üí Vector DB OK
- Si r√©ponses intelligentes ‚Üí LLM activ√© (pas encore fait)

**Status actuel : Mode Vector partiellement fonctionnel, Mode LLM pas encore impl√©ment√©**
