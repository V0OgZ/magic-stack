# ğŸ¯ MCP SERVEUR - VISION & ARCHITECTURE

## ğŸ“Š Ã‰TAT ACTUEL: Deux SystÃ¨mes de Stockage

### 1. **WorldState / GraphCD** (Backend Rust - Port 3001)
- **Quoi**: Ã‰tat du monde en temps rÃ©el, graphe 6D
- **Stockage**: En mÃ©moire, calculs Q*
- **Usage**: 
  - Positions des entitÃ©s
  - Ã‰tats temporels (TW, TE, debt)
  - Paradoxes dÃ©tectÃ©s
  - Chemins calculÃ©s
- **API**: `/api/world-state/nodes`

### 2. **Vector DB** (Port 7500)
- **Quoi**: Base de connaissances, recherche sÃ©mantique
- **Stockage**: Persistant, indexÃ©
- **Usage**:
  - Lore du jeu
  - Backstories des personnages
  - Documentation technique
  - Historique des combats
- **API**: `/search`, `/index`, `/stats`

### 3. **LLM Clippy** (Port 7501)
- **AccÃ¨s ACTUEL**:
  - âœ… Vector DB via API 7500
  - â“ WorldState - pas clair comment
- **Usage**: Commentaires de combat, aide contextuelle

---

## ğŸš€ PROPOSITION: MCP Server (Model Context Protocol)

### Concept
Un serveur **MCP** unifiÃ© qui sert de pont intelligent entre:
- Les assistants IA (Cursor, autres)
- Les diffÃ©rentes sources de donnÃ©es
- Les APIs du projet

### Architecture ProposÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Assistant IA  â”‚
â”‚    (Cursor)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ MCP Protocol
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP Server    â”‚ â† Port 9000 (nouveau)
â”‚  (Controller)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
    â–¼         â–¼      â–¼      â–¼
 Rust API  VectorDB  LLM   Docs
  (3001)   (7500)  (7501)  (local)
```

### FonctionnalitÃ©s MCP

1. **Documentation Dynamique**
   - Sert la doc Ã  jour du projet
   - APIs disponibles en temps rÃ©el
   - Ã‰tat des services

2. **RequÃªtes UnifiÃ©es**
   ```python
   # Au lieu de:
   rust_data = fetch("http://localhost:3001/...")
   vector_data = fetch("http://localhost:7500/...")
   
   # On fait:
   mcp.query("get hero position and backstory")
   # â†’ MCP interroge les 2 sources et unifie
   ```

3. **Context Injection**
   - Injecte automatiquement le contexte pertinent
   - WorldState pour les calculs
   - VectorDB pour le lore
   - Combine les deux pour Clippy

---

## ğŸ“ IMPLÃ‰MENTATION RAPIDE

### Option 1: Python MCP Server (30 min)
```python
# mcp_server.py
from flask import Flask, jsonify
import requests

app = Flask(__name__)

@app.route('/mcp/context/<entity>')
def get_context(entity):
    # RÃ©cupÃ¨re WorldState
    world = requests.get(f"http://localhost:3001/api/entities/{entity}")
    
    # RÃ©cupÃ¨re VectorDB
    lore = requests.post("http://localhost:7500/search", 
                        json={"query": entity})
    
    # Combine et retourne
    return jsonify({
        "world_state": world.json(),
        "knowledge": lore.json(),
        "apis": get_available_apis()
    })

@app.route('/mcp/docs')
def get_docs():
    # Retourne la doc Ã  jour
    return serve_markdown_as_json()
```

### Option 2: IntÃ©gration dans Java (1h)
- Ajouter un `MCPController.java`
- Plus robuste, typage fort
- Peut rÃ©utiliser les controllers existants

### Option 3: Extension Rust (2h)
- Module `mcp_bridge` dans le backend Rust
- Performance maximale
- AccÃ¨s direct au GraphCD

---

## ğŸ¯ BÃ‰NÃ‰FICES

1. **Pour Vincent**:
   - Une seule API Ã  comprendre
   - Documentation toujours Ã  jour
   - Debug facilitÃ©

2. **Pour les Assistants IA**:
   - Context complet automatique
   - Pas besoin de jongler entre APIs
   - Comprend mieux le projet

3. **Pour le Jeu**:
   - Clippy plus intelligent
   - Fusion WorldState + Lore
   - Extensible pour futurs mages

---

## âœ… TODO IMMÃ‰DIAT

1. [ ] CrÃ©er `mcp_server.py` basique
2. [ ] Endpoint `/mcp/context` qui fusionne les donnÃ©es
3. [ ] Endpoint `/mcp/apis` qui liste tout
4. [ ] Tester avec Clippy pour les commentaires
5. [ ] Documenter le protocole MCP

---

## ğŸ”— RÃ‰FÃ‰RENCES

- MCP Protocol: https://modelcontextprotocol.io/
- UtilisÃ© par: Claude Desktop, Cursor (bientÃ´t?)
- Notre cas: Bridge custom pour notre architecture

---

**STATUS**: Ã€ IMPLÃ‰MENTER
**PRIORITÃ‰**: HAUTE si Ã§a simplifie vraiment
**TEMPS ESTIMÃ‰**: 30min - 2h selon l'option
